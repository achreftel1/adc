{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ3lr4NJqA4gFRxcdepInU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achreftel1/adc/blob/main/keras_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kSJE-CwWyfBk",
        "outputId": "40fd606c-1f12-4ab4-aeda-cd969a949f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.3744 - loss: 1.8050\n",
            "Epoch 1: val_loss improved from inf to 1.39571, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 466ms/step - accuracy: 0.3744 - loss: 1.8049 - val_accuracy: 0.5209 - val_loss: 1.3957 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:26\u001b[0m 555ms/step - accuracy: 0.5938 - loss: 1.1837\n",
            "Epoch 2: val_loss improved from 1.39571 to 1.39541, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 91ms/step - accuracy: 0.5938 - loss: 1.1837 - val_accuracy: 0.5205 - val_loss: 1.3954 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.5113 - loss: 1.4292\n",
            "Epoch 3: val_loss improved from 1.39541 to 1.31902, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 465ms/step - accuracy: 0.5113 - loss: 1.4292 - val_accuracy: 0.5430 - val_loss: 1.3190 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:49\u001b[0m 531ms/step - accuracy: 0.4688 - loss: 1.3404\n",
            "Epoch 4: val_loss improved from 1.31902 to 1.31880, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 91ms/step - accuracy: 0.4688 - loss: 1.3404 - val_accuracy: 0.5440 - val_loss: 1.3188 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.5292 - loss: 1.3651\n",
            "Epoch 5: val_loss improved from 1.31880 to 1.30558, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 441ms/step - accuracy: 0.5292 - loss: 1.3651 - val_accuracy: 0.5466 - val_loss: 1.3056 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:03\u001b[0m 310ms/step - accuracy: 0.4688 - loss: 1.3233\n",
            "Epoch 6: val_loss improved from 1.30558 to 1.30429, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 91ms/step - accuracy: 0.4688 - loss: 1.3233 - val_accuracy: 0.5470 - val_loss: 1.3043 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.5439 - loss: 1.3250\n",
            "Epoch 7: val_loss improved from 1.30429 to 1.27090, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 464ms/step - accuracy: 0.5439 - loss: 1.3250 - val_accuracy: 0.5612 - val_loss: 1.2709 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:01\u001b[0m 309ms/step - accuracy: 0.5938 - loss: 1.4186\n",
            "Epoch 8: val_loss improved from 1.27090 to 1.27089, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - accuracy: 0.5938 - loss: 1.4186 - val_accuracy: 0.5599 - val_loss: 1.2709 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5469 - loss: 1.3075\n",
            "Epoch 9: val_loss improved from 1.27089 to 1.26143, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m692s\u001b[0m 443ms/step - accuracy: 0.5469 - loss: 1.3075 - val_accuracy: 0.5611 - val_loss: 1.2614 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:02\u001b[0m 309ms/step - accuracy: 0.5625 - loss: 1.1676\n",
            "Epoch 10: val_loss improved from 1.26143 to 1.26121, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - accuracy: 0.5625 - loss: 1.1676 - val_accuracy: 0.5614 - val_loss: 1.2612 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5513 - loss: 1.2908\n",
            "Epoch 11: val_loss improved from 1.26121 to 1.24476, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 442ms/step - accuracy: 0.5513 - loss: 1.2908 - val_accuracy: 0.5660 - val_loss: 1.2448 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:07\u001b[0m 312ms/step - accuracy: 0.5625 - loss: 1.0957\n",
            "Epoch 12: val_loss improved from 1.24476 to 1.24425, saving model to vgg_model.keras\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 69ms/step - accuracy: 0.5625 - loss: 1.0957 - val_accuracy: 0.5674 - val_loss: 1.2443 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.5515 - loss: 1.2873"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d3bd0b5ad4d6>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m history = model.fit(datagen.flow(x_train, y_train, batch_size=32), \n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    341\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     )\n\u001b[0;32m--> 343\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    344\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Define the VGG model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new layers on top of the base model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint('vgg_model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=int(len(x_train) / 32),\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[checkpoint, early_stopping, reduce_lr])\n",
        "\n",
        "# Plot the error vs epoch graph\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}